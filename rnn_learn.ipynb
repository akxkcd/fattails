{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_learn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/akxkcd/fattails/blob/master/rnn_learn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "gieiBsDREoTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHwBZklmEvs8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x1Vs0k9_EqeG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "input_size = 1  # one-hot size\n",
        "hidden_size = 2  # output from the RNN. 5 to directly predict one-hot\n",
        "batch_size = 1   # one sentence\n",
        "sequence_length = 1  # One by one\n",
        "num_layers = 1  # one-layer rnn\n",
        "\n",
        "class Model(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
        "    \n",
        "  def forward(self, hidden, x):\n",
        "    x = x.view(batch_size, sequence_length, input_size)\n",
        "\n",
        "    # Propagate input through RNN\n",
        "    # Input: (batch, seq_len, input_size)\n",
        "    # hidden: (num_layers * num_directions, batch, hidden_size)\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "    return hidden, out.view(-1, num_classes)\n",
        "  \n",
        "  def init_hidden(self):\n",
        "    # Initialize hidden and cell states\n",
        "    # (num_layers * num_directions, batch, hidden_size)\n",
        "    return Variable(torch.zeros(num_layers, batch_size, hidden_size))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PpMlt3dFCeM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cc65d08a-6a31-4d1f-afcf-3b95bae6d8d6"
      },
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (rnn): RNN(1, 2, batch_first=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JQraLvQQQ39H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2dbbc468-7459-4c84-a280-5dd8b91a4969"
      },
      "cell_type": "code",
      "source": [
        "one_hot_lookup = [[1],  # 0\n",
        "                  [0],  # 1\n",
        "                  [0],  # 2\n",
        "                  [0],  # 3\n",
        "                  [0]]  # 4\n",
        "id2char = ['h', 'i', 'e', 'l', 'o']\n",
        "\n",
        "x_data = [0, 1, 0, 1, 0, 0]\n",
        "# y_data = [1, 0, 1, 0, 1, 1]\n",
        "y_data = [0, 0, 1, 0, 1, 0]\n",
        "\n",
        "x_one_hot = [one_hot_lookup[i] for i in x_data]\n",
        "print(\"x_one_hot:\", x_one_hot)\n",
        "\n",
        "# As we have one batch of samples, we will change them to variables only once\n",
        "inputs = Variable(torch.Tensor(x_one_hot))\n",
        "labels = Variable(torch.LongTensor(y_data))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  loss = 0\n",
        "  hidden = model.init_hidden()\n",
        "\n",
        "  # print(\"predicted string: \")\n",
        "  for input, label in zip(inputs, labels):\n",
        "    # print(input.size(), label.size())\n",
        "    hidden, output = model(hidden, input)\n",
        "    val, idx = output.max(1)\n",
        "    # print(id2char[idx.data[0]])\n",
        "    loss += criterion(output, label)\n",
        "    if epoch == 99:\n",
        "      print(\"{} output: {} label:{}\".format(input.data[0], idx.data[0], label.data[0]))\n",
        "  # print(\", epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data[0]))\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(\"Learning finished!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_one_hot: [[1], [0], [1], [0], [1], [1]]\n",
            "1.0 output: 0 label:0\n",
            "0.0 output: 0 label:0\n",
            "1.0 output: 1 label:1\n",
            "0.0 output: 0 label:0\n",
            "1.0 output: 1 label:1\n",
            "1.0 output: 0 label:0\n",
            "Learning finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OYMVhAudRD2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}